# 虾皮面经

## 笔试

70.爬楼梯

146.lru-缓存

[123. 买卖股票的最佳时机 III](https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-iii/)

110.平衡二叉树

213.打家劫舍-ii

## 1.为什么投Shopee

**我**选**择**Shopee**主**要**有**以**下**几**个**原**因**：

1. **Shopee**是**东**南**亚**领**先**的**电**商**平**台**，**业**务**规**模**大**，**技**术**挑**战**性**强**，**能**提**供**很**好**的**成**长**空**间
2. **Shopee**的**技**术**团**队**在**分**布**式**系**统**、**高**并**发**处**理**等**方**面**有**深**厚**积**累**，**能**学**到**很**多**前**沿**技**术
3. **电**商**领**域**是**我**非**常**感**兴**趣**的**领**域**，**能**将**自**己**的**技**术**能**力**应**用**到**实**际**业**务**场**景**中
4. **Shop**ee**的**国**际**化**工**作**环**境**和**工**程**师**文**化**很**吸**引**我

## 2.常用的设计模式包括：

1. 单例模式 - 确保一个类只有一个实例
2. 工厂模式 - 创建对象而不暴露创建逻辑
3. 观察者模式 - 定义对象间的一对多依赖关系
4. 策略模式 - 定义算法族，可以互相替换
5. 装饰器模式 - 动态地给对象添加职责

在项目中，我使用单例模式管理缓存客户端，使用工厂模式创建不同的支付处理器，使用观察者模式实现事件通知机制。

## 3. 饿汉式单例是线程安全的吗？

是的，饿汉式单例是线程安全的。因为实例在类加载时就创建了，由JVM保证只会加载一次，所以不存在多线程并发创建实例的问题。


## 4. Https加密过程

HTTPS加密过程(TLS握手)：

1. 客户端发送ClientHello，包含支持的加密算法等
2. 服务端返回ServerHello，选定加密算法并发送证书
3. 客户端验证证书，生成预主密钥并用证书公钥加密发送
4. 服务端用私钥解密获得预主密钥
5. 双方用预主密钥生成会话密钥
6. 后续通信使用会话密钥加密

## 5.RPC传输性能优化

RPC传输性能优化：

1. 选择高效的序列化方式(Protobuf等)
2. 使用长连接减少连接建立开销
3. 压缩传输数据
4. 批量请求减少网络往返
5. 异步非阻塞IO
6. 选择合适的传输协议(TCP/HTTP2等)


## 6.MySQL间隙锁

间隙锁(Gap Lock)：

1. 解决幻读问题
2. 锁定索引记录之间的间隙
3. 在REPEATABLE READ隔离级别下使用
4. 防止其他事务在间隙中插入新记录
5. 与记录锁组合成next-key lock




###  **MySQL 事务隔离级别？**

**MySQL InnoDB 存储引擎支持四种标准的事务隔离级别，用于控制多个并发事务之间数据的可见性。从低到高依次是：**

* **读未提交 (Read Uncommitted)**

  * **现象**：一个事务可以读取到另一个事务**尚未提交**的修改。这会导致**脏读 (Dirty Read)**。
  * **优点**：并发性能最高。
  * **缺点**：数据一致性最差，实际生产中基本不用。
* **读已提交 (Read Committed)**

  * **现象**：一个事务只能读取到另一个事务**已经提交**的数据。
  * **解决了**：脏读。
  * **问题**：在同一个事务中，两次执行相同的查询，可能会得到不同的结果，因为在这两次查询之间，另一个事务可能提交了新的修改。这叫做**不可重复读 (Non-Repeatable Read)**。
  * **说明**：这是大多数数据库（如 Oracle, SQL Server）的默认隔离级别。
* **可重复读 (Repeatable Read)**

  * **现象**：在一个事务开始后，无论其他事务是否提交修改，该事务内多次执行相同的查询，返回的结果集都是一样的。
  * **解决了**：不可重复读。
  * **问题**：理论上无法解决**幻读 (Phantom Read)**，即在一个事务中，第一次查询返回了N行，第二次查询返回了M行（M>N），多出来的就是“幻影”行。但 MySQL InnoDB 引擎通过**Next-Key Lock（间隙锁+行锁）** **机制解决了这个问题。**
  * **说明**：这是 **MySQL InnoDB 的默认隔离级别**。
* **串行化 (Serializable)**

  * **现象**：最高的隔离级别。强制事务串行执行，即一个一个地处理。所有读操作都会隐式地加上共享锁，写操作会加上排他锁。
  * **解决了**：脏读、不可重复读、幻读。
  * **缺点**：并发性能最差，因为会大量发生锁竞争。

| **隔离级别**        | **脏读 (Dirty Read)** | **不可重复读 (Non-Repeatable Read)** | **幻读 (Phantom Read)** |
| ------------------------- | --------------------------- | ------------------------------------------ | ----------------------------- |
| **读未提交**        | **可能**              | **可能**                             | **可能**                |
| **读已提交**        | **不可能**            | **可能**                             | **可能**                |
| **可重复读 (默认)** | **不可能**            | **不可能**                           | **不可能 (InnoDB)**     |
| **串行化**          | **不可能**            | **不可能**                           | **不可能**              |

---

### 2. 可重复读和读已提交有啥区别？

 **这两者是面试中最常被对比的级别，它们的核心区别在于**对数据“快照”的创建时机不同**，这背后依赖于** **MVCC (多版本并发控制)** **机制。**

* **读已提交 (Read Committed, RC)**
* **快照时机**：**事务中的每一条** **SELECT** **语句执行时**，都会创建一个新的Read View（读视图/快照）。
* **表现**：它保证了你每次读到的都是**当前最新的、已提交**的数据。因此，如果另一个事务在你两次查询之间提交了更新，你第二次查询就会看到新的数据，导致了“不可重复读”。
* **可重复读 (Repeatable Read, RR)**

  * **快照时机**：**仅在事务中的第一条** **SELECT** **语句执行时**，创建一个Read View，并且整个事务期间都复用这个Read View。
  * **表现**：由于整个事务都使用同一个旧版本的快照，所以无论其他事务如何提交，它看到的数据始终是事务刚开始时的那个状态，从而保证了“可重复读”。

 **一句话总结**：**RC是“语句级别”的快照，RR是“事务级别”的快照。**

---

### 3. MySQL 的 undo log 主要作用是啥？

**undo log** **是 InnoDB 存储引擎中的一个至关重要的组件，它有两个核心作用：**

* **实现事务的原子性 (回滚)**

  * **undo log** **记录的是数据的**逻辑反向操作**。例如，当你** **INSERT** **一条记录时，它会记录一条对应的** **DELETE** **日志；当你** **UPDATE** **一条记录时，它会记录下修改前的“旧值”。**
  * **如果事务执行过程中发生错误或者用户执行了** **ROLLBACK** **语句，系统就可以利用** **undo log** **中的信息将数据恢复到事务开始之前的状态，从而保证事务的原子性。**
* **实现多版本并发控制 (MVCC)**

  * **这是** **undo log** **更重要的作用。当一个事务需要读取某行数据时，如果这行数据正在被另一个事务修改，系统不会直接加锁等待，而是会通过这行数据隐藏的指针，去** **undo log** **中查找**适合当前事务可见的旧版本**。**
  * **这个机制使得“读”和“写”操作可以不加锁并发执行，极大地提高了数据库的并发性能。前面提到的**RC**和**RR**隔离级别的实现，正是依赖于** **undo log** **提供的历史数据版本。**

---

### 4. 怎么实现分布式锁？

**当多个服务实例（部署在不同机器上）需要互斥地访问一个共享资源时，就需要分布式锁。常见实现方式有三种：**

* **基于 Redis 实现**

  * **原理**：利用 Redis 命令 **SET key value NX PX milliseconds** **的原子性。**NX **确保只有当 key 不存在时才能设置成功，**PX **设置一个过期时间以防止客户端崩溃导致死锁。**
  * **加锁**：**SET resource_name random_value NX PX 30000**。设置成功，则获取锁。**random_value** **用于标识加锁的客户端，保证“谁加锁，谁解锁”。**
  * **解锁**：使用 Lua 脚本，先 **GET** **key 判断 value 是否与自己设置的** **random_value** **相同，如果相同再执行** **DEL**。这样保证了原子性，防止误删别人的锁。
  * **优点**：性能高。
  * **缺点**：

    * **锁超时问题**：如果业务执行时间超过锁的过期时间，锁会自动释放，可能被其他线程获取。解决方案是“看门狗（Watchdog）”机制，在锁未释放前定期续期。
  * **主从切换问题**：如果 Redis Master 节点宕机，锁信息未同步到 Slave，Slave 升级为 Master 后，其他客户端可能再次获取到锁，导致锁失效。Redlock 算法尝试解决这个问题，但争议较大。
* **基于 ZooKeeper/etcd 实现**

  * **原理**：利用 ZK 的**有序临时节点**。
  * **加锁**：所有客户端都在一个指定的父节点（如 **/locks**）下尝试创建一个**临时顺序节点**。创建成功后，获取父节点下的所有子节点，判断自己创建的节点序号是否是最小的。如果是，则获取锁成功。
  * **等待与解锁**：如果不是最小的，就监听（watch）比自己序号小的前一个节点。当监听到前一个节点被删除的事件时，再次检查自己是否为最小序号。当客户端业务完成或崩溃时，由于是临时节点，与 ZK 的会话断开后节点会自动删除，从而实现锁的释放。
  * **优点**：可靠性非常高，不存在 Redis 的超时和主从问题，天然支持可重入和阻塞等待。
  * **缺点**：性能相较于 Redis 较低，实现也更复杂。
* **基于数据库实现**

  * **原理**：利用数据库的**唯一索引**或**排他锁**。
  * **方式一（唯一索引）**：创建一个锁表，对资源名 **resource_name** **字段建立唯一索引。尝试** **INSERT** **一条记录，成功则获取锁，失败则说明锁已被占用。解锁时** **DELETE** **该记录。**
  * **优点**：实现简单。
  * **缺点**：性能开销大，依赖数据库，且不具备自动过期和高可用特性，容易因客户端崩溃导致死锁。

---

### 5. 100 万考生按分数排序，有啥思路？

**这是一个典型的海量数据排序问题，需要考虑数据特点。**

* **数据量分析**：100万考生。假设每个考生的信息（如准考证号+分数）占16字节，总数据量约为 **100万 * 16B ≈ 16MB**。这个数据量完全可以**放入内存**处理。
* **数据特征分析**：考生的分数通常是**整数**，且范围是**有限且确定**的（例如，高考分数在 0-750 之间）。

**思路一：通用排序算法**

* **快速排序**：最常用的通用排序算法，平均时间复杂度 O(N log N)。对于100万数据，效率非常高。

**思路二：利用数据特征的非比较排序算法（更优）**

* **这正是下一个问题的答案。**

---

### 6. 除了归并，根据分数特点有更好的排序算法吗？

**当然有，计数排序 (Counting Sort) 是最优解。**

* **原理**：计数排序是一种非比较排序算法，它利用一个辅助数组（桶）来统计每个分数出现的次数，然后根据统计结果直接生成有序序列。
* **适用场景**：数据是整数，且范围 **k** **不大。本题中分数范围（如0-750）远小于数据量（100万），是计数排序的完美应用场景。**
* **步骤**：

  * **创建一个大小为 751 的计数数组** **count**，**count[i]** **用来记录分数为** **i** **的考生人数。**
* **遍历 100 万考生数据，对于每个考生的分数** **score**，执行 **count[score]++**。
* **遍历计数数组** **count**，从 **count[750]** **到** **count[0]**（假设按分数从高到低排序），根据每个分数的计数值，直接输出结果。
* **时间复杂度**：O(N + k)，其中 N 是考生数量，k 是分数范围。在这里是 O(100万 + 751)，基本上是线性时间复杂度，远快于 O(N log N) 的快速排序。

---

### 7. 内存不够的情况下，怎么给大文件排序？

 **当文件大小远超内存容量时（例如，100GB 的文件在 1GB 内存的机器上排序），就需要使用**外部排序 (External Sort)**。**

  **外部排序的核心思想是**分治 + 归并**。**

* **分块 (Chunking & Sorting)**
* **将大文件分成若干个小块（chunk），每个小块的大小可以被内存容纳（例如，1GB）。**
* **依次将每个小块读入内存。**
* **使用高效的内存排序算法（如快速排序）对这个小块进行排序。**
* **将排序后的小块（称为一个**有序的“顺串” (run)**）写入磁盘上的一个临时文件。**
* **重复此过程，直到整个大文件都被处理成一个个有序的临时文件。**
* **多路归并 (K-way Merge)**

  * **现在我们有了一堆有序的临时文件。下一步是将它们合并成一个最终的有序大文件。**
  * **从每个临时文件中读取一小部分数据（例如，第一个元素或前几个元素）到内存中的**输入缓冲区**。**
  * **使用一个**最小堆 (Min-Heap) **数据结构，将每个缓冲区中的第一个元素放入堆中。**
  * **循环执行以下操作，直到所有数据都被处理：**

    * **从最小堆中取出堆顶元素（即当前所有缓冲区中的最小值）。**
    * **将这个最小元素写入到最终的输出文件中。**
    * **从该元素所在的输入缓冲区中，取出下一个元素，并将其放入最小堆中。**
    * **如果某个输入缓冲区被耗尽，就从对应的临时文件中读取下一批数据进来。如果临时文件已读完，则不再向堆中添加元素。**



### **1. MySQL 索引的实现？**

**MySQL的索引实现主要与存储引擎相关，其中最常用的是InnoDB，它使用**B+树**数据结构来实现索引。**

**为什么选择B+树？**

  **这主要是为了**适配磁盘I/O的特性**，核心目标是**尽可能减少磁盘的读写次数**。**

* **多叉结构，高度低**：
  与二叉树不同，B+树是“矮胖”的多叉树。每个节点可以存储大量的关键字和指针，这使得树的高度非常低。比如，一个高度为3的B+树就可以存储千万级别的数据。因为每次查询最多只需要经过树的高度次磁盘I/O，极大地提升了查询效率。
* **非叶子节点只存索引和指针**：
  在B+树中，只有叶子节点才存储完整的数据（或指向数据的指针）。非叶子节点仅存储索引键（key）和指向下一层节点的指针（pointer）。这使得非叶子节点可以容纳更多的索引项，进一步降低了树的高度。
* **叶子节点形成有序双向链表**：
  所有的叶子节点通过一个双向链表连接起来。这个特性对于**范围查询**（如 **WHERE id > 100**）和排序（**ORDER BY**）操作极为有利。一旦定位到范围的起始点，只需沿着链表顺序遍历即可，无需回溯树的上层结构。

  **小结**：B+树通过**低树高**、**高扇出**和**有序叶子节点链表**的设计，完美地平衡了查询效率和磁盘I/O成本，是关系型数据库索引的理想选择。

---

### 2. MySQL 的事务隔离级别？读未提交有什么优点？

**MySQL InnoDB支持四种标准的事务隔离级别，从低到高依次是：**

* **读未提交 (Read Uncommitted)**：一个事务可以读取到另一个事务**未提交**的数据。这会导致**脏读**。
* **读已提交 (Read Committed)**：一个事务只能读取到其他事务**已提交**的数据。解决了脏读，但可能出现**不可重复读**。
* **可重复读 (Repeatable Read)**：在一个事务内，多次读取同一份数据，结果总是一致的。解决了不可重复读，但理论上存在**幻读**（但InnoDB通过Next-Key Lock解决了）。**这是MySQL的默认级别。**
* **串行化 (Serializable)**：最高的隔离级别，强制事务串行执行，避免了所有并发问题，但性能最差。

**“读未提交”有什么优点？**

**这是一个常见的面试“陷阱题”。**

* **理论上的优点**：它的并发性能是最高的，因为读操作几乎不需要等待任何写锁，加锁和解锁的开销最小。
* **实际上的结论**：**这个优点在实际生产中毫无意义**。因为它破坏了事务最基本的隔离性，连“脏数据”都能读到，这会导致严重的数据不一致问题。因此，**在任何严肃的生产环境中，都绝对不会使用“读未提交”这个隔离级别**。

**在回答时，一定要先说出理论优点，然后立刻强调它的致命缺点和不适用性，以展现你成熟的工程思维。**

---

### 3. MySQL 可重复读原理？

**MySQL InnoDB在“可重复读”隔离级别下的实现，核心依赖于**MVCC (Multi-Version Concurrency Control，多版本并发控制) **机制。**

 **核心原理**：

* **创建快照 (Read View)**：
  当一个事务**第一次执行**SELECT**语句**时，InnoDB会为这个事务创建一个“快照”（Read View）。这个快照记录了在创建这一刻，数据库中所有活跃（未提交）的事务ID列表。
* **版本链 (Undo Log)**：
  数据库的每一行记录，除了存储数据本身，还隐藏了两个重要字段：创建该版本的事务ID (**DB_TRX_ID**) 和一个指向前一个版本的指针 (**DB_ROLL_PTR**)，这个指针串联起了存储在**undo log**中的历史版本，形成了一个**版本链**。
* **可见性判断**：
  当事务要读取某一行数据时，它会拿着自己的Read View去和这行数据的最新版本进行比较：

  * **如果这行数据的事务ID**对当前Read View可见**（即这个版本是在Read View创建前就已提交的，或者就是本事务自己修改的），那么就直接读取。**
* **如果不可见（即这个版本是在Read View创建后才开启的事务修改的，或者是Read View创建时还活跃的事务修改的），那么就顺着版本链往前找，直到找到一个对当前Read View可见的版本为止。**

 **一句话总结**：**“可重复读”之所以能实现，是因为整个事务期间都复用第一次查询时创建的那个Read View，所以它看到的数据版本被“定格”在了事务开始的那个瞬间。**

---

### 4. MySQL 的 IN 查询会走索引吗？

**答案是：不一定，这取决于MySQL优化器的成本估算。**

**MySQL的优化器是基于成本的（Cost-Based Optimizer）。它会估算不同执行计划的成本（主要是I/O和CPU消耗），然后选择成本最低的一个。**

* **会走索引的情况**：
  当**IN**列表中的**元素数量较少**，并且索引的**选择性（Selectivity）较好**时，优化器会倾向于使用索引。它会把**IN**查询看作是多个等值查询的组合，通过**index range scan**（索引范围扫描）来执行，效率很高。
* **不走索引的情况**：
  当**IN**列表中的**元素数量非常多**时（比如成百上千个），优化器可能会做出不同的判断。它会认为，通过索引进行大量离散的、随机的I/O（包括回表操作），其总成本可能比一次**全表扫描（Full Table Scan）** **还要高。全表扫描是顺序I/O，在某些情况下效率反而更高。此时，优化器就会放弃使用索引。**

 **如何确定**：在实际工作中，判断**IN**查询是否走了索引的最可靠方法是使用**EXPLAIN**命令来分析其执行计划。

---

### 5. 乐观锁和悲观锁的区别？

**这是两种不同的并发控制思想。**

* **悲观锁 (Pessimistic Locking)**

  * **思想**：非常“悲观”，认为数据冲突的概率很高，所以**在操作数据之前，总是先加锁**，确保在自己操作期间，别人无法修改。
  * **实现**：在数据库层面，主要通过**SELECT ... FOR UPDATE**或**SELECT ... LOCK IN SHARE MODE**等语句实现，依赖数据库的锁机制。
  * **优点**：数据安全性高，实现简单。
  * **缺点**：加锁和释放锁的开销大，并发性能差，容易导致线程阻塞和死锁。
  * **适用场景**：**写多读少**，冲突激烈的场景，如金融交易、秒杀库存扣减的核心环节。
* **乐观锁 (Optimistic Locking)**

  * **思想**：非常“乐观”，认为数据冲突的概率很低，所以**操作数据时不加锁**，而是在**提交更新时，去检查数据是否被其他线程修改过**。
  * **实现**：通常通过在表中增加一个**版本号（**version**）字段**或**时间戳字段**来实现。更新时，**UPDATE ... SET version = version + 1 WHERE id = ? AND version = ?**。如果**WHERE**条件中的**version**匹配，说明数据未被修改，更新成功；否则更新失败，由业务逻辑决定是重试还是报错。
  * **优点**：避免了加锁开销，并发性能高。
  * **缺点**：实现相对复杂，如果冲突频繁，会导致大量重试，反而降低性能。
  * **适用场景**：**读多写少**，冲突较少的场景，如更新用户信息、文章点赞等。


**这是一个经典的分布式系统问题，没有完美的“银弹”，所有方案都是在**成本、性能和一致性**之间做权衡。**

**首先，要放弃的错误方案：**

* **先更新缓存，再更新数据库**：绝对不行。如果更新缓存成功，但数据库更新失败，缓存中将存在脏数据，且后续无法修正。
* **先更新数据库，再更新缓存**：在并发场景下有问题。假设线程A更新数据库，线程B也更新数据库，B先完成，更新了缓存。然后A后完成，又用旧值更新了缓存，导致数据不一致。

**主流的解决方案有以下几种，按推荐程度排序：**

#### 方案一：Cache-Aside Pattern (旁路缓存模式) - 推荐

**这是业界最常用、最经典的模式。**

* **读操作**：

  * **应用先从缓存中读取数据。**
* **如果缓存命中（Hit），则直接返回。**
* **如果缓存未命中（Miss），则从数据库中读取数据。**
* **读取成功后，将数据放入缓存，然后返回。**
* **写操作（关键）**：

  * **先更新数据库**。
* **再直接删除缓存**。

 **为什么是删除缓存，而不是更新缓存？**
因为删除操作是**幂等的**，并且逻辑简单。如果采用更新，你更新的值可能是一个中间状态的旧值，容易在并发下出错。而删除缓存，下次读请求自然会从数据库加载最新值并回填缓存，保证了数据的最终一致性。

  **这个方案的唯一小瑕疵**：
在极低概率的并发下，可能出现短暂不一致。场景：

* **线程A读取数据，缓存未命中。**
* **线程A去数据库读取了旧值** **V1**。
* **此时线程B更新了数据库，值为** **V2**，并删除了缓存。
* **线程A将它之前读到的旧值** **V1** **写入了缓存。**
  此时，缓存中是旧数据，数据库是新数据。但这种情况发生概率极低，且缓存有过期时间，可以自动修复。

#### 方案二：更新数据库 + 订阅Binlog异步更新缓存 - 进阶推荐

**这是一个更可靠、实现最终一致性的方案，能将缓存更新的逻辑与业务代码解耦。**

* **业务代码在更新数据时，**只负责更新数据库**。**
* **部署一个独立的服务（如使用阿里巴巴的**Canal**），该服务伪装成MySQL的从库，去订阅和解析主库的**binlog**（二进制日志）。**
* **当监听到指定表的数据发生变更（增、删、改）时，这个服务会获取到变更后的数据。**
* **由这个服务来负责**更新或删除**对应的缓存。**

 **优点**：

* **业务解耦**：业务代码只关心核心的数据库操作，不关心缓存。
* **高可靠**：**binlog**是MySQL高可用的基石，订阅**binlog**非常可靠。即使同步服务宕机，也可以根据**binlog**的位置点恢复，保证消息不丢失。
* **最终一致性**：能够保证数据最终会同步到缓存中。

---

### 5. 讲一下你对CAP原理的理解

 **CAP原理是分布式系统设计中最核心、最基础的理论之一。它指出，一个分布式系统**最多只能同时满足以下三个特性中的两个**：**

* **C - Consistency (一致性)**
* **定义**：指**强一致性**或**线性一致性**。当一次写操作成功后，任何后续的读请求，都必须能读到这个最新的值。所有节点在同一时间看到的数据是完全一致的。
* **A - Availability (可用性)**

  * **定义**：任何来自客户端的请求，只要节点没有宕机，就**必须能在有限的时间内给出响应**（不能是错误或超时）。它不保证返回的数据是最新版本。
* **P - Partition Tolerance (分区容错性)**

  * **定义**：当系统中部分节点之间出现网络故障，导致消息丢失或延迟（即产生“网络分区”）时，整个系统**仍然能够继续对外提供服务**。

  **核心结论**：
  在现代分布式系统中，网络分区（P）是**不可避免**的，它是一种必须接受的常态。因此，CAP理论的实际意义是，**当网络分区发生时，你必须在一致性（C）和可用性（A）之间做出选择**。也就是要么选择 **CP**，要么选择 **AP**

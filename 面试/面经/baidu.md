# 百度面经整理

## 面经

实习介绍 20 min

1.在c++中, 什么场合调用拷贝构造函数

**当**用**一**个**已**存**在**的**对**象**初**始**化**一**个**新**对**象**时**，**会**调**用**拷**贝**构**造**函**数**

当类成员或基类需要通过另一个对象初始化时

当对象被插入到STL容器（ `vector`、`list`）中时，会调用拷贝构造函数

当函数**按值返回对象**时，可能会调用拷贝构造函数（取决于编译器优化）

2.纯虚类有虚函数表吗，所有类都有虚函数表吗，虚函数表什么时期建立

只要类中包含至少一个虚函数（包括纯虚函数），编译器就会为该类生成虚函数表（vtable）。
纯虚类（抽象类）即使没有实现任何函数，只要声明了虚函数，就会生成虚函数表。

只有包含虚函数（包括继承的虚函数）的类才会有虚函数表。

普通类（无虚函数）没有虚函数表，也不会有动态多态的开销。

**编译期** ：虚函数表的结构（包含哪些虚函数指针）在编译时确定。

**运行期（程序启动时）** ：虚函数表的具体内存空间在程序加载时初始化（全局数据区），每个类的虚函数表只有一份，被所有该类的对象共享。

**对象构造时** ：当对象被创建时，其虚指针（vptr）会被赋值为对应类的虚函数表地址。

3.++ n 左值还是右值

++n（前置自增）
返回左值（修改后的变量本身）。
可以直接赋值或取地址

n++（后置自增）
返回右值（临时保存的原始值副本）。
不能赋值或取地址

### 面经整理：

#### 1. 为什么父类析构函数要是虚函数？

 **将父类的析构函数声明为虚函数（virtual destructor）是为了**防止内存泄漏**。**

 **具体来说，当使用一个基类指针指向一个派生类对象，并通过这个基类指针**delete**对象时：**

* **如果析构函数是虚函数**：会发生动态绑定，程序会先调用派生类的析构函数，然后再自动调用基类的析构函数。这样可以确保派生类中申请的资源能够被正确释放，然后再释放基类的资源，最终完整地释放整个对象所占的内存。
* **如果析构函数不是虚函数**：则不会发生动态绑定，**delete**操作只会调用基类的析构函数，而不会调用派生类的析构函数。 这将导致派生类独有的资源（例如在派生类构造函数中分配的内存）无法被释放，从而造成内存泄漏。

**因此，只要一个类可能被用作基类，并且可能会通过基类指针删除派生类对象，就应该将其析构函数声明为虚函数。**

#### 2. 普通类的析构函数是虚函数吗？回答：不是 追问：为什么普通类析构不是虚函数？

**普通类（不作为基类的类）的析构函数默认不是虚函数。**

 **原因是**出于性能和效率的考虑**。 C++的设计哲学之一是“不为不使用的东西付出代价”。将一个函数声明为虚函数需要额外的开销：**

* **内存开销**：含有虚函数的类，其实例对象会额外包含一个虚函数指针（vptr），这个指针指向一个虚函数表（vtbl）。这会增加每个对象的大小。
* **性能开销**：调用虚函数时，需要通过虚函数指针查找虚函数表来确定要调用的具体函数地址，这个过程比调用普通成员函数的静态绑定要慢一些。

**如果一个类不打算被继承，或者即使被继承也不会出现通过基类指针删除派生类对象的场景，那么将其析构函数设为虚函数就是一种不必要的开销。因此，默认情况下，普通类的析构函数不是虚函数。**

#### 3. 虚函数怎么实现的？为什么要有虚函数？

 **实现原理：**
C++中虚函数的实现依赖于**虚函数表（vtable或vtbl）**和**虚函数指针（vpointer或vptr）**。

* **虚函数表 (vtbl)**：当一个类中声明了虚函数（或者继承了含有虚函数的基类），编译器会为这个类创建一个静态的虚函数表。 这个表是一个函数指针数组，存放了类中所有虚函数的地址。
* **虚函数指针 (vptr)**：编译器会在该类的每个对象实例的内存布局中增加一个隐藏的成员，即虚函数指针。这个指针在对象构造时被初始化，指向其所属类的虚函数表。
* **调用过程**：当通过基类指针调用一个虚函数时，程序会首先通过对象的虚函数指针找到对应的虚函数表，然后在表中根据函数在编译时确定的索引，找到并调用正确的函数实现。这个过程在运行时确定，因此称为动态绑定或后期绑定。

 **为什么要有虚函数：**
虚函数的存在是为了实现C++的**多态性 (Polymorphism)**。
多态允许我们通过基类的指针或引用来调用派生类中重写（override）的同名函数，从而实现“一个接口，多种实现”。这使得代码更具通用性和可扩展性。例如，可以定义一个基类**Shape**和一个虚函数**draw()**，然后派生出**Circle**、**Square**等类并重写**draw()**。之后就可以用一个**Shape***的数组来存储不同的图形对象，并统一调用它们的**draw()**方法来绘制各自的形状，而无需关心指针指向的具体是哪种图形。

#### 4. set和map底层怎么实现的？有什么不一样吗？

**std::set**和**std::map**（以及**multiset**和**multimap**）在C++标准库中通常是基于**红黑树（Red-Black Tree）**实现的。红黑树是一种自平衡的二叉搜索树。

 **共同点**：

* **底层结构**：都是红黑树，这保证了其元素的有序性。
* **时间复杂度**：插入、删除、查找操作的平均和最坏时间复杂度都是对数时间，即 **O(log N)**。
* **有序性**：遍历**set**或**map**时，得到的元素是自动排序的。

 **不一样的地方**：

* **存储内容**：
* **std::set**：存储的是**键（key）**的集合。每个元素都是唯一的，只存储键本身。可以看作是一个不允许重复且自动排序的集合。
* **std::map**：存储的是**键值对（key-value pair）**。每个键是唯一的，并且每个键都映射到一个值。
* **用途**：

  * **set** **主要用于判断某个元素是否存在于集合中，以及对集合进行去重和排序。**
* **map** **主要用于建立键和值之间的映射关系，通过键来快速存取对应的值。**

 **从C++11开始，标准库还引入了**std::unordered_set**和**std::unordered_map**，它们底层是基于**哈希表（Hash Table）**实现的。它们不保证元素有序，但在理想情况下，插入、删除和查找的时间复杂度可以达到平均** **O(1)**。

#### 5. 智能指针了解吗？有哪些？有什么不同？

**了解。智能指针是C++中用于管理动态分配内存（堆内存）的对象，它能利用**RAII（Resource Acquisition Is Initialization，资源获取即初始化）**的特性，在智能指针对象离开作用域时自动释放其所管理的内存，从而有效避免内存泄漏。**

**主要的智能指针有三种：**

* **std::unique_ptr** **(独占式指针)**：

  * **特点**：同一时间内，只有一个**unique_ptr**可以拥有对其所管理对象的所有权。
* **所有权**：所有权是独占的，**unique_ptr**不支持拷贝构造和拷贝赋值操作，防止多个指针指向同一资源而导致重复释放。但它可以通过**std::move**来转移所有权。
* **用途**：适用于需要明确对象所有权，防止资源被意外共享的场景。例如，工厂函数返回一个新创建对象的指针。
* **std::shared_ptr** **(共享式指针)**：

  * **特点**：允许多个**shared_ptr**共同拥有同一个对象的所有权。
* **所有权**：它内部维护一个引用计数。每当有一个新的**shared_ptr**指向该资源时，引用计数加1；每当一个**shared_ptr**被销毁（例如离开作用域）或指向其他资源时，引用计数减1。当引用计数变为0时，它会自动释放所管理的资源。
* **用途**：适用于需要多个地方共享和管理同一份资源，且无法确定哪个是最后一个使用者的场景。
* **std::weak_ptr** **(弱引用指针)**：

  * **特点**：它是一种不控制对象生命周期的智能指针，它指向一个由**shared_ptr**管理的对象，但不会增加该对象的引用计数。
* **用途**：主要用于解决**shared_ptr**可能导致的**循环引用**问题。 当两个对象通过**shared_ptr**相互引用时，它们的引用计数永远不会变为0，从而导致内存泄漏。将其中一个引用关系改为**weak_ptr**即可打破循环。**weak_ptr**不能直接访问对象，需要通过调用**lock()**方法返回一个**shared_ptr**来临时获取所有权并安全地访问对象。

#### 6. 怎么样会出现内存泄漏？除了程序有未释放的资源还有什么？

 **内存泄漏的核心原因是**程序动态申请的内存（通常在堆上），在使用完毕后没有被正确释放，导致这块内存无法被再次分配使用**。**

 **除了常见的**new**/**malloc**之后忘记**delete**/**free**导致的资源未释放，还有以下几种情况可能导致内存泄漏：**

* **基类析构函数非虚**：正如第一个问题所讨论的，通过基类指针删除派生类对象时，如果基类析构函数不是虚函数，会导致派生类部分的资源未被释放。
* **循环引用**：在使用**std::shared_ptr**时，如果两个或多个对象通过**shared_ptr**形成一个闭环的引用关系，它们的引用计数将永远无法降为0，导致所管理的内存都无法被释放。
* **异常安全问题**：如果在**new**和**delete**之间发生了异常，且没有相应的**try-catch**块来保证**delete**的执行，那么**delete**语句将被跳过，从而造成内存泄漏。智能指针可以很好地解决这个问题。
* **隐式内存分配**：某些库函数或系统调用可能会在内部进行内存分配，如果开发者没有意识到这一点并且没有调用对应的释放函数，也可能导致泄漏。
* **不当的容器使用**：例如，向一个容器中存放了裸指针，当容器被销毁时，它只会销毁指针本身占用的内存，而不会释放指针所指向的内存。正确的做法是使用智能指针容器，或者在销毁容器前手动遍历并释放每个指针指向的内存。

#### 7. Cmake知道吗，做什么的，为什么要用？有什么好处？

**知道。**

* **做什么的**：CMake是一个开源的、跨平台的**构建系统生成工具**。它本身不直接编译代码，而是根据一个名为**CMakeLists.txt**的配置文件，生成对应编译器环境（如Visual Studio的**.sln**工程文件、Unix/Linux下的**Makefile**等）的标准构建文件，然后再由这些构建文件来完成实际的编译、链接工作。
* **为什么要用/有什么好处**：

  * **跨平台**：这是CMake最核心的优势。开发者只需要编写一套**CMakeLists.txt**文件，就可以在Windows、Linux、macOS等不同操作系统上生成相应的工程文件并进行编译，极大地提高了项目的可移植性。
* **简化和自动化构建过程**：对于大型复杂项目，手动编写Makefile或配置Visual Studio工程是非常繁琐和易错的。CMake可以用更简洁、更高级的命令来管理源代码文件、查找库、设置编译选项等，使构建过程更加自动化和可靠。
* **管理依赖**：CMake提供了强大的命令（如**find_package**）来查找和链接项目所需的第三方库，能够自动处理库的路径和编译链接选项，简化了依赖管理。
* **与测试框架集成**：CMake可以方便地与CTest等测试框架集成，实现编译、测试、打包等一体化流程。
* **社区和生态**：CMake已经成为C++项目事实上的标准构建工具，拥有庞大的社区和丰富的文档，几乎所有主流的C++库和项目都支持CMake。

### 网络:

#### 1. http和https的区别？怎么加密的？对称和非对称了解吗？

 **区别**：

* **安全性**：HTTP是超文本传输协议，数据以**明文**方式传输，不提供任何数据加密，安全性差。HTTPS（安全超文本传输协议）是HTTP的安全版，它在HTTP和TCP之间加入了一个SSL/TLS安全层，对传输的数据进行**加密**处理，保证了数据的机密性、完整性和身份认证。
* **端口**：HTTP使用默认端口**80**，HTTPS使用默认端口**443**。
* **证书**：HTTPS需要向证书颁发机构（CA）申请SSL证书，用于验证服务器的身份。而HTTP不需要。
* **连接过程**：HTTPS比HTTP多了一个SSL/TLS的握手过程，用于协商加密算法和交换密钥。

 **加密方式**：
HTTPS的加密过程是**对称加密**和**非对称加密**的结合使用。

* **非对称加密**：用于在TLS握手阶段安全地**协商和传输对称加密的密钥**。

  ***过程**：客户端向服务器请求，服务器将其公钥发送给客户端。客户端生成一个随机的对称密钥（称为会话密钥），然后用服务器的公钥对其进行加密，再发送给服务器。服务器用自己的私钥**解密，获取到这个会话密钥。
* **特点**：公钥加密的数据只有对应的私钥才能解开，安全性高，但计算复杂，速度慢。
* **对称加密**：用于在握手结束后的**实际数据传输**阶段。

  * **过程**：客户端和服务器都使用上一步协商好的那个**会话密钥**，对传输的HTTP报文进行加密和解密。
* **特点**：加密和解密使用同一个密钥，计算开销小，速度快，适合对大量数据进行加密。

**通过这种方式，HTTPS结合了两种加密方式的优点：利用非对称加密的安全性解决了密钥传输的问题，然后利用对称加密的高效性来处理实际的通信内容。**

#### 2. tcp三次握手四次挥手过程？为什么需要三次？两次不行吗？

 **三次握手（建立连接）**：

* **第一次握手**：客户端向服务器发送一个SYN（同步序列编号）报文，并进入**SYN_SENT**状态，等待服务器确认。
* **第二次握手**：服务器收到SYN报文后，如果同意连接，会回复一个SYN+ACK（确认）报文，同时自己也进入**SYN_RCVD**状态。
* **第三次握手**：客户端收到服务器的SYN+ACK报文后，会向服务器发送一个ACK报文。此报文发送完毕，客户端和服务器都进入**ESTABLISHED**（已建立连接）状态，完成三次握手。

  **为什么需要三次握手，两次不行吗**？
  主要原因是为了**防止已失效的连接请求报文突然又传到服务器，从而导致服务器资源浪费**。
* **场景假设**：如果采用两次握手。客户端发送了一个SYN请求，但由于网络延迟，这个请求滞留了。客户端没收到ACK，会超时重传一个新的SYN请求，这次正常建立了连接，传输数据，然后断开连接。
* **问题**：一段时间后，那个滞留的旧SYN请求终于到达了服务器。如果是两次握手，服务器收到后会认为是一个新的连接请求，立即发送ACK并进入连接状态，等待客户端发送数据。但此时客户端实际上并没有发起新连接的意图，它会忽略服务器的ACK，不会发送任何数据。这样，服务器就会一直单方面地维持着这个连接，白白浪费了资源。
* **三次握手如何解决**：有了第三次握手，服务器在收到旧的SYN并发出SYN+ACK后，由于收不到客户端的最终ACK确认，就知道这可能是一个失效的请求，就不会真正建立连接，从而避免了资源浪费。

 **四次挥手（断开连接）**：

* **第一次挥手**：客户端（或服务器）发送一个FIN（结束）报文，用来关闭从客户端到服务器的数据传送。客户端进入**FIN_WAIT_1**状态。
* **第二次挥手**：服务器收到FIN报文后，发送一个ACK报文作为确认。此时TCP连接处于半关闭状态，即客户端不再发送数据，但服务器可能还有数据要发送，仍然可以发送数据。
* **第三次挥手**：服务器将最后的数据发送完毕后，向客户端发送一个FIN报文，用于关闭从服务器到客户端的数据传送。服务器进入**LAST_ACK**状态。
* **第四次挥手**：客户端收到FIN报文后，发送一个ACK报文作为确认，并进入**TIME_WAIT**状态。经过2*MSL（最长报文段寿命）时间后，客户端关闭连接。服务器收到ACK后，立即关闭连接。

#### 3. 网络编程的基本步骤，需要调那几个函数？

**以TCP的Socket编程为例，基本的步骤和函数如下：**

 **服务器端**：

* **socket()**：创建一个套接字，指定协议族（如AF_INET表示IPv4）、套接字类型（如SOCK_STREAM表示TCP）和协议。
* **bind()**：将创建的套接字与一个本地的IP地址和端口号绑定起来。
* **listen()**：使套接字进入监听状态，准备接收客户端的连接请求，并设置一个等待连接的队列长度。
* **accept()**：阻塞等待客户端的连接请求。一旦有客户端连接，**accept()**会返回一个新的套接字，这个新的套接字用于与该客户端进行通信。
* **read()**/**recv()** **和** **write()**/**send()**：使用新的套接字与客户端进行数据收发。
* **close()**：关闭套接字，释放资源。

 **客户端**：

* **socket()**：创建一个套接字。
* **connect()**：向指定的服务器IP地址和端口号发起连接请求。
* **write()**/**send()** **和** **read()**/**recv()**：连接成功后，与服务器进行数据收发。
* **close()**：关闭套接字。

#### 4. 客户端崩了，服务端这边会怎么样？会一直连接吗？那不是很占用资源？

**客户端崩溃，服务端**不会**一直无限期地保持连接。TCP协议本身有机制来处理这种情况。**

* **心跳机制/保活定时器（Keepalive）**：TCP协议栈内部有一个保活定时器。当一个连接长时间没有数据交互时，服务器端的TCP层会主动发送一个探测报文（Keepalive Probe）给客户端。

  * **如果客户端正常，会回复一个ACK。**
* **如果客户端已经崩溃，无法响应，服务器将不会收到任何回复。**
* **服务器会进行**超时重传**，在多次重传（通常有次数限制）探测报文后，如果仍然没有收到任何响应，服务器就会认为客户端已经断开，从而主动关闭这个连接，释放占用的资源。**
* **应用层心跳**：除了TCP层面的Keepalive，很多应用程序也会在应用层自己实现心跳机制。比如，服务器定期向客户端发送一个“心跳包”，并要求客户端回复。如果在规定时间内没有收到回复，服务器就认为客户端已下线，并主动断开连接。这种方式更灵活，可以根据业务需求自定义检测频率和超时时间。

**所以，即使客户端异常崩溃，通过TCP的保活机制或应用层心跳机制，最终都能检测到并断开连接，避免了资源的永久占用。**

#### 5. 既然提到了超时重传，那说一说拥塞控制吧

**拥塞控制是TCP协议的一个核心机制，目的是防止过多的数据注入到网络中，导致网络过载（路由器缓存溢出、分组丢失等），从而保证网络的稳定性和效率。**

**TCP的拥塞控制主要通过四个核心算法来工作，这些算法围绕着一个叫做**拥塞窗口（cwnd）**的变量展开，它决定了发送方在收到确认前可以连续发送的数据量。**

* **慢启动（Slow Start）**：

  * **目的**：连接刚建立时，为了探测网络的承载能力，发送方不会一开始就发送大量数据。
* **过程**：cwnd初始值很小（通常为1-10个MSS）。每收到一个ACK，cwnd就增加一个MSS。这样，cwnd会呈**指数级增长**（每经过一个RTT，cwnd就翻倍）。
* **拥塞避免（Congestion Avoidance）**：

  * **目的**：当网络接近拥挤时，减缓cwnd的增长速度，避免网络拥塞。
* **过程**：当cwnd增长到一个预设的**慢启动阈值（ssthresh）**后，慢启动阶段结束，进入拥塞避免阶段。此时，cwnd不再指数增长，而是**线性增长**（每个RTT只增加一个MSS）。
* **拥塞发生（Congestion Detection）**：

  * **判断依据**：TCP通过两种方式判断拥塞发生：
  * **超时重传**：发送方在等待一个ACK时超时，这被认为是网络拥塞的强烈信号。
  * **快速重传（3个重复ACK）**：发送方连续收到3个对于同一个报文段的重复ACK，这表明该报文段之后的某个报文段丢失了，网络可能开始出现拥塞。
* **快速恢复（Fast Recovery）**：

  * **过程（针对快速重传）**：当发生快速重传时，TCP认为网络拥塞不是很严重。
  * **将**ssthresh**设置为当前cwnd的一半。**
  * **将**cwnd**也设置为ssthresh（有的实现是ssthresh + 3*MSS）。**
  * **然后进入拥塞避免阶段，开始线性增长。**
* **过程（针对超时重传）**：当发生超时重传时，TCP认为网络拥塞非常严重。

  * **将**ssthresh**设置为当前cwnd的一半。**
    * **将**cwnd**直接降为1个MSS。**
    * **重新开始**慢启动**过程。**

**这四个算法协同工作，动态调整发送速率，使得TCP能够在保证可靠传输的同时，最大限度地利用网络带宽，并避免造成网络拥堵。**

### 系统：

#### 1. 进程线程区别？协程呢？

 **进程 (Process)**：

* **定义**：是操作系统进行**资源分配和调度**的基本单位。一个正在执行的程序可以看作是一个进程。
* **资源**：每个进程都有自己独立的地址空间、内存、文件句柄等系统资源。进程间的资源是隔离的。
* **开销**：创建、销毁和切换进程的开销很大，因为涉及到系统资源的分配和回收，以及上下文的切换。

 **线程 (Thread)**：

* **定义**：是**CPU调度和执行**的基本单位，可以看作是“轻量级的进程”。一个进程可以包含多个线程。
* **资源**：同一进程内的所有线程共享该进程的地址空间和大部分资源（如代码段、数据段、堆、文件句柄等）。但每个线程有自己独立的程序计数器、寄存器和栈。
* **开销**：线程的创建、销毁和切换开销远小于进程，因为它们共享资源，切换时只需保存和恢复少量私有状态。

 **协程 (Coroutine)**：

* **定义**：是一种**用户态的、更轻量级的线程**，也称为“纤程”或“绿色线程”。它的调度完全由程序员在代码中控制，而非操作系统。
* **资源**：协程运行在线程之上，一个线程可以包含成千上万个协程。协程之间的切换不涉及线程切换，更不涉及进程切换。
* **开销**：协程的创建和切换开销极小，因为它不涉及操作系统内核的上下文切换，只是简单的函数调用和CPU寄存器状态的保存/恢复。
* **特点**：非常适合用于处理高并发I/O密集型任务，因为它可以在一个线程内实现异步非阻塞的编程模型，避免了线程的频繁创建和切换带来的开销。

  **总结**：**进程**是资源单位，**线程**是执行单位，**协程**是用户态的、由程序控制的执行单位。从开销和粒度上看：**进程 > 线程 > 协程**。

#### 2. 线程这么实现同步？除了条件变量和锁还有什么办法？

**线程同步的目的是为了协调多个线程对共享资源的访问，防止数据竞争和不一致。除了**锁（Mutex）**和**条件变量（Condition Variable）**，还有以下几种常见的同步方法：**

* **信号量 (Semaphore)**：

  * **是一个计数器，用于控制同时访问某个特定资源的线程数量。**
* **P**操作（或**wait**）会使信号量计数减1，如果计数器变为负数，则线程阻塞。
* **V**操作（或**signal**）会使信号量计数加1，如果计数器小于等于0，则唤醒一个等待的线程。
* **信号量可以看作是锁的一般化形式，当信号量初始值为1时，就相当于一个互斥锁。**
* **原子操作 (Atomic Operations)**：

  * **指那些不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何上下文切换。**
* **例如，C++11** **`<atomic>`**头文件中提供的**std::atomic**模板，可以对整型、布尔型、指针等类型进行原子性的读、写、加、减、交换等操作。
* **对于简单的计数器或状态标志的更新，使用原子操作比使用锁的效率高得多，因为它避免了加锁、解锁的开销和内核态切换。**
* **读写锁 (Read-Write Lock)**：

  * **一种更细粒度的锁，它区分了读操作和写操作。**
* **允许多个线程同时对共享资源进行**读**操作，但只允许一个线程进行**写**操作。当有线程在进行写操作时，其他任何读或写操作都会被阻塞。**
* **适用于“读多写少”的场景，可以显著提高并发性能。**
* **屏障 (Barrier)**：

  * **一种同步机制，它要求一组线程必须都到达某个点（屏障点）之后，才能继续一起往下执行。**
* **常用于多线程协同完成一个分阶段任务的场景，确保所有线程都完成了当前阶段的工作后，再一起进入下一个阶段。**

#### 3. lru算法知道吗？为什么这么设计？

**知道。LRU（Least Recently Used）即**最近最少使用**算法，是一种常见的缓存淘汰策略。**

* **核心思想**：如果一个数据在最近一段时间没有被访问，那么它在将来被访问的概率也很低。因此，当缓存空间不足时，应该优先淘汰那些最长时间未被使用的数据。
* **为什么这么设计**：
  这种设计是基于**程序访问的局部性原理（Principle of Locality）**。该原理指出，程序在一段时间内访问的存储器位置往往是集中于一个较小的范围内的，包括：

  * **时间局部性**：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。
* **空间局部性**：如果一个数据项被访问，那么与它地址相邻的数据项也很可能很快被访问。

  **LRU算法正是利用了**时间局部性**。它保留了那些“最近被使用过”的数据，因为根据时间局部性原理，这些数据有很大概率会很快被再次访问。淘汰“最久未使用”的数据，是因为这些数据再次被访问的概率相对较低。通过这种方式，LRU旨在提高缓存的命中率，从而提升系统性能。**
* **经典实现**：
  为了同时满足快速查找（判断数据是否存在）和快速更新/淘汰（维护访问顺序）的需求，LRU通常使用**哈希表（HashMap） + 双向链表（Doubly Linked List）**的数据结构来实现。

  * **哈希表**：提供 O(1) 时间复杂度的查找能力，存储键到链表节点的映射。
* **双向链表**：维护数据的访问顺序。每次访问（get或put）一个数据时，就将对应的节点移动到链表的尾部（表示最近使用）。当需要淘汰数据时，直接淘汰链表头部（表示最久未使用）的节点即可。

### 手撕：

#### 1. 单例模式

**好的。单例模式是一种确保一个类只有一个实例，并提供一个全局访问点的设计模式。这里我写一个C++11之后的线程安全的懒汉式实现（Meyers' Singleton）。**

**code**C++

```
#include <iostream>

class Singleton {
public:
    // 3. 提供一个全局的静态访问方法
    static Singleton& getInstance() {
        // 使用静态局部变量，在C++11及以后版本是线程安全的
        static Singleton instance; 
        return instance;
    }

    // 禁止外部拷贝和赋值
    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;
  
    void showMessage() {
        std::cout << "Hello from Singleton instance!" << std::endl;
    }

private:
    // 1. 构造函数私有化，防止外部直接创建实例
    Singleton() {
        std::cout << "Singleton instance created." << std::endl;
    }

    // 2. 析构函数可以设为私有或公有，这里设为默认公有
    ~Singleton() {
        std::cout << "Singleton instance destroyed." << std::endl;
    }
};

int main() {
    std::cout << "Main started." << std::endl;

    // 多次调用获取的是同一个实例
    Singleton& s1 = Singleton::getInstance();
    s1.showMessage();

    Singleton& s2 = Singleton::getInstance();
    s2.showMessage();

    // 检查地址是否相同
    if (&s1 == &s2) {
        std::cout << "s1 and s2 are the same instance." << std::endl;
    }

    std::cout << "Main finished." << std::endl;
  
    return 0;
}
```

 **代码说明**：

* **这种实现利用了函数内静态变量的特性：它只会在第一次调用**getInstance()**时被初始化，并且C++11标准保证了这种初始化过程是线程安全的。**
* **构造函数和拷贝控制成员（拷贝构造、拷贝赋值）被设为私有或删除，防止了外部通过这些方式创建或复制实例。**
* **这种方式也避免了需要手动管理内存释放的问题，实例会在程序结束时自动销-毁。**

#### 2. 小于k的最小子数组

**您是指 “和” 小于 K 的最小长度子数组，还是 “和” 大于等于 K 的最小长度子数组？通常这个问题是问“和大于等于K的最小长度子数组”。我先按这个经典的题目来做，如果理解有误，您可以随时纠正。**

**题目：给定一个正整数数组** **nums** **和一个正整数** **k**，找出该数组中满足其总和大于等于 **k** **的连续子数组的最小长度。如果不存在符合条件的子数组，返回0。**

**这个问题可以使用**滑动窗口**的方法来解决，时间复杂度可以达到O(N)。**

### 智能指针，协程

* **智能指针**：就像我刚才在项目中提到的，智能指针是现代C++中进行资源管理的核心工具，它利用RAII（资源获取即初始化）的机制，将堆上分配的资源（如内存、文件句柄、socket等）与一个栈上对象的生命周期绑定，当对象离开作用域时，资源会被自动释放。

  * **std::unique_ptr**：提供独占所有权，保证同一时间只有一个指针指向资源。我用它来管理那些生命周期清晰、不需要共享的数据缓冲区。
* **std::shared_ptr**：通过引用计数实现共享所有权。我用它来管理TCP连接对象，因为连接对象需要在主线程、I/O线程、心跳检测模块等多个地方被引用，**shared_ptr**能确保只有当所有引用都消失时，连接资源才被真正释放。
* **std::weak_ptr**：它是一种弱引用，不增加引用计数，主要用来解决**shared_ptr**可能导致的循环引用问题。
* **协程**：协程可以理解为一种用户态的、由程序员控制调度的“轻量级线程”。它的切换开销非常小，因为它不涉及操作系统内核的上下文切换，仅仅是函数调用栈的切换。在我的项目中，虽然没有直接使用C++20标准的**co_await**等关键字，但我们实现的基于状态机的异步处理模型，其核心思想与协程是一致的：即**在一个线程内实现多个任务的协作式调度**。当一个任务遇到I/O阻塞时，它会主动让出执行权，让CPU去执行其他就绪的任务，而不是让整个线程阻塞。这种方式非常适合高并发的I/O密集型场景，能用极少的线程处理海量的连接。

### rtos和linux调度的区别

**RTOS（实时操作系统）和Linux（通用操作系统）的调度策略有本质的区别，这源于它们设计目标的根本不同。**

* **调度目标**：

  * **RTOS**：核心目标是**实时性**和**确定性**。它必须保证任务在规定的最后期限（Deadline）内完成。调度的首要原则是**可预测性**。
* **Linux**：核心目标是**公平性**和**高吞吐量**。它要保证系统中的每个进程都能获得合理的CPU时间片，同时最大化系统的整体处理能力。
* **调度算法**：

  * **RTOS**：通常采用**基于优先级的抢占式调度**。调度器非常简单直接：在任何时刻，永远是处于就绪态的、优先级最高的那个任务在运行。高优先级任务可以立即抢占低优先级任务。
* **Linux**：调度算法复杂得多。例如现在主流的CFS（Completely Fair Scheduler，完全公平调度器），它不直接使用优先级，而是通过一个虚拟运行时间（vruntime）来记录每个进程的运行情况，每次都选择vruntime最小的进程来运行，力求所有进程获得“完全公平”的CPU时间。
* **延迟（Latency）**：

  * **RTOS**：中断延迟和任务切换延迟非常低，并且是**有界的、可预测的**。这是实现硬实时的关键。
* **Linux**：延迟相对较高，且**不确定**。因为内核比较庞大，处理流程复杂，在某些情况下（如内核锁）可能是不可抢占的，所以无法提供硬实时的保证。（当然，通过打上**PREEMPT_RT**实时补丁可以使Linux具备软实时甚至接近硬实时的能力，但其内核机制与原生RTOS还是有区别的）。

**总结来说，RTOS像一个纪律严明的特种部队，一切为了完成“准时”这个核心任务；而Linux则像一个繁忙的大城市交通调度系统，力求让所有车辆都能公平地通过，并保持整体交通流畅。**

### tcp/ip协议，socket是处于什么层

* **TCP/IP协议**：通常指TCP/IP协议簇，它是一个分层模型，经典划分为四层：

  * **应用层（Application Layer）**：负责处理特定的应用程序细节，如HTTP、FTP、DNS等协议。
* **传输层（Transport Layer）**：为两台主机上的应用程序提供端到端的通信，主要协议是TCP（可靠的、面向连接的）和UDP（不可靠的、无连接的）。
* **网络层（Internet Layer）**：负责将数据包从源地址发送到目的地址，主要协议是IP协议。
* **网络接口层（Network Interface Layer）**：负责处理与物理网络（如以太网、Wi-Fi）相关的细节。
* **Socket所处的层**：Socket本身并不是TCP/IP协议簇的一员，它是一种**编程接口（API）**。我们可以把它看作是**介于应用层和传输层之间的一个抽象层**。

  **操作系统为应用程序提供了一组称为Socket API的函数（如**socket()**,** **bind()**, **connect()**等）。应用程序（应用层）通过调用这些函数来使用传输层（TCP/UDP）提供的服务，从而实现网络通信，而无需关心传输层以下的复杂实现细节。所以，Socket是应用层用来访问传输层服务的“门”。

1. **阻塞IO：用普通的壶烧水**

   * **你把水壶放到炉子上，然后就**站在那儿一直盯着它**，什么也不干，直到水烧开。**
   * **优点**：很简单，你不用想别的事情，水开了你肯定第一时间知道。
   * **缺点**：在你等待的这段时间里（IO等待数据），你（CPU）被完全占用了，无法去做其他任何事情（比如切菜、看电视），效率极低。
2. **非阻塞IO：用普通壶烧水，但你很忙**

   * **你把水壶放到炉子上，然后**立马回头去干别的事**（比如切一刀菜）。但你不知道水开了没，所以你**每隔几秒钟就要回过头去看一眼**水壶。**
   * **优点**：你没有被“卡”在烧水这一件事上，等待期间可以去做别的事。
   * **缺点**：你需要**反复地去检查**（轮询），这会消耗你大量的精力和时间（CPU时间片被浪费在大量无效的IO调用上），如果检查得太频繁，你可能也干不好别的事。

---

### 从系统和代码层面看

| **特性**     | **IO阻塞 (Blocking I/O)**                                                                            | **IO非阻塞 (Non-blocking I/O)**                                                      |
| ------------ | ---------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| **调用行为** | **如果数据未就绪，调用会**一直等待（挂起/睡眠）**，直到数据就绪才返回。**                            | **如果数据未就绪，调用会**立即返回一个错误码**。**                                   |
| **CPU使用**  | **线程被挂起，**不占用CPU**。CPU可以去调度其他线程。**                                               | **线程保持运行状态，需要**反复轮询**，会持续占用CPU（形成“忙等待”）。**              |
| **编程模型** | **简单，代码是同步的，易于理解。**data = socket.read()**，下一行代码执行时，**data**一定是有效的。** | **复杂，需要应用程序自己处理返回的错误码，并设计轮询逻辑。代码通常在一个循环体内。** |
| **适用场景** | **适用于连接数少，并发度不高的场景。**                                                               | **单独使用较少，因为它会导致CPU空转。它真正的威力在于和** **IO多路复用** **结合。**  |

### IO非阻塞的进化：IO多路复用

**单纯的非阻塞IO因为“忙等待”的问题，效率并不高。因此，它通常与**IO多路复用 (I/O Multiplexing) **技术（如** **select**, **poll**, **epoll**）结合使用，这才是构建高性能网络服务的关键。

**我们继续用烧水的比喻：**

* **IO多路复用 + 非阻塞IO：用会叫的水壶烧水**

  * **你现在有了很多高科技的**会叫的水壶**（多个非阻塞的socket），你把它们都放到炉子上。然后你告诉**管家**（**epoll**），“这些水壶哪个开了就叫我”。**
  * **然后你就可以**安心地去看书睡觉**了（线程被挂起，不占用CPU）。**
  * **当某个水壶的水开了（某个socket数据准备好了），管家（**epoll**）会来叫醒你。你被唤醒后，直接去处理那个已经烧开的水壶即可。**

**这种模型的好处是：**

* **一个线程（你）可以同时监控大量的IO事件（很多水壶）。**
* **在等待期间，线程是睡眠的，完全不消耗CPU。**

**像 Nginx、Redis、Node.js 这类高性能中间件，其底层都采用了 IO多路复用 + 非阻塞IO 的模型来实现高并发。**

### 总结

* **阻塞IO**：简单，但一个线程只能处理一个IO，并发能力差。
* **非阻塞IO**：给了应用程序更大的控制权，但简单的轮询会空耗CPU。
* **非阻塞IO + IO多路复用**：结合了两者的优点，是实现高并发网络编程的基石。它允许单线程（或少量线程）同时管理成千上万个网络连接，并且在没有事件发生时不会空耗CPU。

#### 4. 进程和线程

**进程和线程是操作系统中两个核心的概念，它们的主要区别在于对资源的管理和调度的单位不同。**

* **进程 (Process)**：是操作系统进行**资源分配和调度**的基本单位。可以看作是一个正在运行的程序的实例。每个进程都有自己独立的内存空间、文件句柄、数据段等，进程间的资源是相互隔离的。因此，进程的创建、销毁和切换开销都比较大。
* **线程 (Thread)**：是**CPU调度和执行**的基本单位，也被称为轻量级进程。一个进程可以包含多个线程，这些线程**共享**所属进程的绝大部分资源（如代码区、堆、全局变量等），但每个线程拥有自己独立的栈、程序计数器和寄存器。由于资源共享，线程的创建、销毁和切换开销远小于进程。

#### 5. 线程同步/线程安全

* **线程同步**：是指在多线程环境下，通过特定的机制（如锁、信号量等）来控制多个线程对共享资源的访问顺序，以避免数据竞争和状态不一致的问题，确保程序能按照预期的逻辑执行。
* **线程安全**：指的是一个函数、函数库或对象在多线程环境中被并发调用时，能够始终表现出正确的行为。如果一段代码是线程安全的，那么开发者就不需要在使用它时额外添加同步控制。

  实现线程同步（从而保证线程安全）的常用方法有：互斥锁（Mutex）、条件变量（Condition Variable）、信号量（Semaphore）、读写锁（Read-Write Lock）、原子操作（Atomic Operations）**等。**

#### 6. 进程间的同步方式，用过哪些？

**进程间的同步和通信（IPC, Inter-Process Communication）方式有很多种，主要包括：**

* **管道（Pipe）**：包括匿名管道和命名管道。匿名管道通常用于具有亲缘关系（如父子）的进程间通信。命名管道则允许无亲缘关系的进程间通信。
* **信号（Signal）**：一种异步通信机制，用于通知接收进程某个事件已经发生。
* **消息队列（Message Queue）**：一个由内核维护的消息链表，它克服了信号承载信息量少、管道只能承载无格式字节流的缺点。
* **共享内存（Shared Memory）**：最高效的IPC方式。它允许多个进程直接读写同一块内存空间，避免了内核态和用户态之间的数据拷贝。但需要配合其他同步机制（如信号量）来保证数据的一致性。
* **信号量（Semaphore）**：本质是一个计数器，常用来控制多个进程对共享资源的访问，也可以作为进程间的同步工具。
* **套接字（Socket）**：最通用的IPC方式，既可以用于同一台主机上的进程间通信，也可以用于不同主机间的网络通信。

**在我的项目中，我主要使用过**套接字**进行跨机器的进程通信，以及在一些简单的场景中使用过**匿名管道**来重定向子进程的输出。对于共享内存，我在学习和实验中接触过，了解它配合信号量一起使用可以实现非常高效的进程间数据共享。**

#### 7. 协程

面试官您好，对于协程，我目前还没有在实际项目中使用过，所以实践经验比较欠缺。但我对它的概念有所了解。

 **我的理解是，协程是一种**用户态的、比线程更轻量级的并发体**。它的调度不是由操作系统内核完成的，而是由程序员在代码中显式地控制。协程的切换开销非常小，因为它不涉及线程上下文的切换，只是函数调用栈的切换。**

 **因此，协程非常适合用在**高并发的I/O密集型**场景。一个线程可以管理成千上万个协程，当一个协程遇到I/O阻塞时，它可以主动让出执行权，让这个线程去执行其他就绪的协程，从而避免了线程的阻塞，极大地提高了系统的并发能力。像Go语言就是天生支持协程的。**

#### 8. 锁，自旋锁和互斥锁区别、读写锁

* **自旋锁 (Spin Lock)**：当一个线程尝试获取一个已经被占用的自旋锁时，该线程**不会被挂起（阻塞）**，而是会进入一个**忙等待**的循环（"自旋"），不断地检查锁是否被释放。

  * **优点**：避免了线程上下文切换的开销。
* **缺点**：在等待期间会持续消耗CPU时间。
* **适用场景**：锁的持有时间非常短，并且CPU资源不那么紧张的场景。在多核处理器上表现较好。
* **互斥锁 (Mutex)**：当一个线程尝试获取一个已经被占用的互斥锁时，该线程会被**挂起（进入睡眠状态）**，并让出CPU。当锁被释放时，操作系统会唤醒这个等待的线程。

  * **优点**：在等待期间不消耗CPU。
* **缺点**：线程的挂起和唤醒涉及到两次上下文切换，有较大的性能开销。
* **适用场景**：锁的持有时间较长，或者并发冲突比较激烈的场景。
* **读写锁 (Read-Write Lock)**：是一种更细粒度的锁，它区分了读操作和写操作。

  * **规则**：“读-读”不互斥（允许多个线程同时读），“读-写”互斥，“写-写”互斥。
* **优点**：相比于互斥锁，它允许多个读线程并发执行，提高了并发性能。
* **适用场景**：**读多写少**的场景，可以大大提高系统的吞吐量。

### 计算机网络

#### 9. tcp三次握手四次挥手

* **三次握手（建立连接）**：

  * **客户端 -> 服务器**：客户端发送一个 **SYN** **包，请求建立连接。**
* **服务器 -> 客户端**：服务器收到后，回复一个 **SYN+ACK** **包，表示同意连接，并确认收到了客户端的请求。**
* **客户端 -> 服务器**：客户端收到服务器的确认后，再发送一个 **ACK** **包。服务器收到后，双方连接建立成功。**
* **四次挥手（断开连接）**：

  * **主动方 -> 被动方**：主动方（如客户端）发送一个 **FIN** **包，表示自己的数据已发送完毕，请求关闭连接。**
* **被动方 -> 主动方**：被动方收到 **FIN** **后，回复一个** **ACK** **包，表示知道了。此时连接处于半关闭状态，被动方可能还有数据要发送。**
* **被动方 -> 主动方**：被动方将自己所有数据都发送完毕后，再发送一个 **FIN** **包，表示自己也准备关闭了。**
* **主动方 -> 被动方**：主动方收到 **FIN** **后，回复一个** **ACK** **包。被动方收到后立即关闭。主动方会等待一个** **2MSL**（最长报文段寿命）的时间再关闭，以确保最后的ACK能被对方收到。

#### 10. tcp和udp区别

| **特性**     | **TCP (传输控制协议)**                                                    | **UDP (用户数据报协议)**                                            |
| ------------ | ------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **连接性**   | **面向连接**的                                                            | **无连接**的                                                        |
| **可靠性**   | **可靠的**（通过确认、重传、流量控制、拥塞控制等机制保证）                | **不可靠的**（尽最大努力交付，不保证到达、顺序和完整性）            |
| **传输方式** | **字节流**（数据没有边界）                                                | **数据报**（每个包都是独立的，有边界）                              |
| **速度**     | **慢**                                                                    | **快**                                                              |
| **开销**     | **大（头部至少20字节，且有复杂的控制逻辑）**                              | **小（头部仅8字节，逻辑简单）**                                     |
| **应用场景** | **要求高可靠性的应用，如文件传输（FTP）、网页浏览（HTTP）、邮件（SMTP）** | **要求实时性、能容忍少量丢包的应用，如视频直播、在线游戏、DNS查询** |

#### 11. udp需要连接吗

 **不需要**。UDP是无连接的协议。发送方在发送数据之前，不需要和接收方建立像TCP那样的三次握手连接。它直接把数据打包成数据报，加上目标地址和端口信息，就往网络上发送了。

### QT

#### 12. 信号和槽

**信号和槽（Signals and Slots）是Qt框架的核心机制，用于实现对象之间的通信。**

* **信号 (Signal)**：当一个对象的状态发生改变时，它可以发射（emit）一个信号。信号是一个特殊的成员函数，只有声明，没有定义。
* **槽 (Slot)**：是一个普通的成员函数或全局函数，它用来响应某个信号。当一个信号被发射时，所有连接到这个信号的槽函数都会被调用。

 **通过** **connect()** **函数可以将一个对象的信号与另一个（或同一个）对象的槽函数关联起来。这种机制使得对象间的通信变得非常灵活，实现了**低耦合**，因为信号的发射者不需要知道谁在接收信号，反之亦然。**

#### 13. 信号和槽函数需要是一个线程的吗

 **不需要**。信号和槽可以在同一个线程中，也可以在不同的线程中。Qt的连接机制支持跨线程通信。

 **connect()** **函数有一个可选的连接类型参数，决定了槽函数的执行方式：**

* **Qt::DirectConnection**（默认，如果信号和槽在同线程）：信号发射时，槽函数在信号发射的线程中**立即同步执行**。
* **Qt::QueuedConnection**（默认，如果信号和槽在不同线程）：信号发射时，一个事件会被放入接收者所在线程的事件队列中。槽函数会在接收者线程处理其事件队列时被**异步执行**。
* **Qt::BlockingQueuedConnection**：与QueuedConnection类似，但是信号发射的线程会阻塞，直到槽函数执行完毕。
* **Qt::AutoConnection**（默认）：Qt会自动判断。如果信号和槽在同一线程，则使用DirectConnection；否则使用QueuedConnection。

**因此，信号和槽是Qt中实现线程安全通信的重要方式。**

### c++

#### 14. 构造函数和析构函数的调用顺序

* **构造函数调用顺序**：

  * **基类构造函数**：如果对象有基类，先调用基类的构造函数。如果有多重继承，按照继承声明的顺序调用。
* **成员对象构造函数**：按照在类中声明的顺序调用成员对象的构造函数。
* **派生类构造函数**：最后执行派生类自身的构造函数体。
* **析构函数调用顺序**：

  * **与构造顺序完全相反**。
* **派生类析构函数**：先执行派生类自身的析构函数体。
* **成员对象析构函数**：按照声明的逆序调用成员对象的析构函数。
* **基类析构函数**：最后调用基类的析构函数。

#### 15. 静态多态和动态多态，实现原理

* **静态多态（编译时多态）**：

  **表现形式**：**函数重载**和**模板**。
* **实现原理**：在**编译阶段**，编译器就能根据函数签名（参数类型、数量）或模板参数来确定具体要调用哪个函数版本。这个过程称为**静态绑定**。它的优点是效率高，没有运行时开销。
* **动态多态（运行时多态）**：

  **表现形式**：通过**继承**体系中的**虚函数**来实现。
* **实现原理**：依赖于**虚函数表（vtable）**和**虚函数指针（vptr）**。

  **当一个类声明了虚函数，编译器会为这个类创建一个静态的虚函数表，存放所有虚函数的地址。**

  **该类的每个对象实例都会包含一个隐藏的虚函数指针，指向其类的虚函数表。**

  **当通过基类指针或引用调用虚函数时，程序在**运行时**通过对象的vptr找到vtable，再从vtable中找到正确的函数地址并调用。这个过程称为**动态绑定**。**

#### 16. 指针和引用

* **本质**：指针是一个变量，存储的是内存地址。引用是变量的别名，不占独立内存空间（或说编译器层面隐藏了）。
* **初始化**：引用在定义时**必须**初始化，且不能再改变其指向。指针可以不初始化，也可以随时改变其指向。
* **空值**：指针可以为**nullptr**，引用不能为空。
* **sizeof**：**sizeof(指针)**得到的是指针自身的大小（4/8字节）。**sizeof(引用)**得到的是其引用的对象的大小。
* **安全性**：引用比指针更安全，因为它杜绝了空指针和野指针的问题。

#### 17. static

**static** **关键字用于改变变量的存储周期和链接属性，或限定函数/成员的作用域。**

* **修饰局部变量**：使其存储在**静态存储区**，生命周期延长至整个程序运行期间，但作用域不变。函数多次调用时，该变量只初始化一次。
* **修饰全局变量/函数**：将其链接属性变为**内部链接 (internal linkage)**，使其作用域被限定在当前编译单元（.cpp文件）内，避免了不同文件间的命名冲突。
* **修饰类成员变量**：该变量变为**静态成员变量**，属于整个类，而非某个对象。所有对象共享这一个变量。它必须在类外进行初始化。
* **修饰类成员函数**：该函数变为**静态成员函数**，不与任何特定对象绑定，没有**this**指针。它只能访问静态成员变量和静态成员函数。可以通过类名直接调用（**ClassName::func()**）。

#### 18. 介绍智能指针 ，shared_ptr的实现原理，用过哪些？

**智能指针是C++中用于自动管理动态分配内存的对象，它利用RAII（资源获取即初始化）的特性，在智能指针对象离开作用域时自动释放所管理的内存，从而有效避免内存泄漏和悬挂指针等问题。**

**我用过的主要有三种：**

* **std::unique_ptr**：独占式所有权，轻量高效，不能拷贝，只能移动。
* **std::shared_ptr**：共享式所有权，允许多个指针共同管理同一份资源。
* **std::weak_ptr**：一种弱引用，用于辅助**shared_ptr**解决循环引用的问题。

 **shared_ptr**的实现原理**：**
shared_ptr**内部通常包含两个指针：**

* **一个指向**被管理资源**的指针。**
* **一个指向**控制块（Control Block）**的指针。**

**这个**控制块**是实现其核心功能的关键，它在资源第一次被**shared_ptr**管理时被创建，并由所有指向该资源的**shared_ptr**共享。控制块中至少包含：**

* **一个**引用计数 (Reference Count)**：记录有多少个**shared_ptr**正指向该资源。当一个新的**shared_ptr**拷贝构造或赋值时，计数加1；当一个**shared_ptr**析构或指向其他资源时，计数减1。当引用计数变为0时，自动释放被管理的资源。**
* **一个**弱引用计数 (Weak Count)**：记录有多少个**weak_ptr**指向该资源。当弱引用计数也变为0时，控制块本身才被释放。**

#### 19. c++和c语言区别

**C++是在C语言基础上发展而来的，是C的超集，但两者在编程思想和语言特性上有巨大差异：**

* **编程范式**：C是**面向过程**的，而C++是**面向对象**的，支持封装、继承和多态。
* **核心特性**：C++引入了**类 (class)** **和对象的概念，这是最核心的区别。**
* **内存管理**：C++使用**new/delete**进行动态内存管理，支持构造函数和析构函数自动管理资源（RAII）。C使用**malloc/free**。
* **标准库**：C++拥有强大的**STL（标准模板库）**，提供了丰富的容器、算法和迭代器。
* **其他特性**：C++还增加了**模板（泛型编程）、引用、函数重载、命名空间、异常处理、智能指针**等许多现代语言特性。

#### 20. 面向对象三大特性，为什么要封装、private\public\protected private只能内部调用，怎么绕过？ 虚函数和纯虚函数

* **三大特性**：封装、继承、多态。
* **为什么要封装**：

  * **信息隐藏**：隐藏对象的内部实现细节，只暴露必要的接口给外部。
* **安全性**：保护内部数据不被外部随意修改，只能通过预设的接口进行访问，保证了数据的完整性和一致性。
* **降低耦合**：内部实现的变化不会影响到外部调用者，提高了代码的模块化和可维护性。
* **private/public/protected**：

  * **public**：类内、子类、类外都可以访问。
* **protected**：类内和子类可以访问，类外不行。
* **private**：只有类内可以访问。
* **怎么绕过private**：

  * **友元 (Friend)**：通过在类内声明一个**友元函数**或**友元类**，可以授权它们直接访问该类的**private**和**protected**成员。这是C++语言本身提供的“受控的”绕过封装的方式。
* **指针技巧（不推荐）**：通过指针操作，强行访问对象的私有成员内存地址。这是一种非常危险且破坏封装性的黑客行为，会使代码变得脆弱和不可维护。
* **虚函数和纯虚函数**：

  * **虚函数 (Virtual Function)**：在基类中用**virtual**关键字声明的成员函数。它允许在派生类中被**重写 (override)**，从而实现动态多态。基类中的虚函数可以有自己的实现。
* **纯虚函数 (Pure Virtual Function)**：一种特殊的虚函数，它在基类中**只有声明，没有定义**，其声明形式为 **virtual void func() = 0;**。
* **区别**：包含纯虚函数的类称为**抽象类**，抽象类**不能被实例化**。派生类**必须**重写基类所有的纯虚函数，才能成为一个可实例化的具体类。纯虚函数为派生类强制规定了一个必须实现的接口。

### 是否熟悉Linux

**是的，我非常熟悉Linux。我的主要开发环境就是基于Linux（例如Ubuntu），熟悉常用的Shell命令、文件系统操作、gcc/g++和gdb调试工具、以及Makefile和CMake构建系统。**
